{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2689e94-1cd7-43de-abab-2303b20c8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a957a19-ef5c-4066-93b3-9d48a7e1be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, label_size):\n",
    "        super().__init__()\n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Convolutional Layer\n",
    "        # (in_channels, out_channels, kernel_size)\n",
    "        # first in channel is 1 because its greyscale\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # (6, 350, 350) -> (6, 173, 173)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # (6, 173, 173) -> (16, 84, 84)\n",
    "\n",
    "        # Linear Layer\n",
    "        self.fc1 = nn.Linear(16 * 84 * 84, 120) # shape of image after pooling twice (16, 84, 84)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, label_size)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d60e8da-e051-4929-b474-d2c7f0e00f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 1, 350, 350])\n",
      "torch.Size([200, 1, 350, 350])\n",
      "tensor([5, 4, 4, 1, 5, 5, 6, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 4, 4, 5, 4,\n",
      "        4, 5, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 5, 4, 5, 5, 4, 4, 4, 6, 4, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 4, 5, 4,\n",
      "        4, 5, 4, 5, 5, 5, 4, 4, 4, 5, 4, 4, 4, 5, 4, 4, 5, 4, 5, 4, 4, 4, 7, 4,\n",
      "        4, 5, 5, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 5, 4, 5, 4, 6, 4, 4, 5, 4, 5, 5,\n",
      "        4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 1, 4, 6, 5, 5, 5, 4, 4, 4, 1, 4, 6, 5, 5,\n",
      "        4, 5, 4, 5, 4, 4, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4, 4, 4, 5, 5, 4, 5, 4,\n",
      "        5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 4, 4, 4, 5, 5, 4, 5, 4, 5, 4, 5, 4, 4, 4,\n",
      "        4, 4, 5, 4, 4, 0, 5, 5, 4, 4, 5, 4, 5, 5, 5, 5, 4, 4, 4, 5, 4, 5, 4, 5,\n",
      "        4, 4, 4, 4, 5, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 5, 5,\n",
      "        5, 4, 4, 4, 4, 5, 5, 1, 6, 5, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 5, 5, 5, 4, 4, 5, 4, 4, 5, 4, 5, 4, 5, 4, 4, 0, 5, 1, 4, 4, 4, 4,\n",
      "        4, 4, 4, 5, 4, 4, 4, 4, 5, 5, 5, 4, 4, 5, 4, 5, 1, 5, 4, 5, 4, 4, 5, 4,\n",
      "        5, 4, 0, 5, 5, 4, 4, 6, 5, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 5,\n",
      "        5, 6, 4, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 5, 4, 1, 5, 5, 4, 4, 5, 4, 5, 4,\n",
      "        4, 5, 4, 4, 5, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5,\n",
      "        5, 5, 5, 4, 4, 4, 0, 0, 4, 4, 5, 4, 6, 5, 4, 4, 5, 4, 4, 4, 5, 4, 4, 5,\n",
      "        4, 4, 4, 5, 1, 5, 4, 4, 5, 5, 5, 4, 4, 4, 5, 4, 5, 2, 1, 4, 5, 4, 4, 4,\n",
      "        5, 5, 6, 5, 4, 4, 5, 4, 5, 4, 5, 5, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 5,\n",
      "        5, 4, 4, 5, 4, 5, 4, 4, 5, 4, 5, 4, 4, 4, 4, 5, 4, 5, 5, 4, 4, 5, 4, 4,\n",
      "        5, 4, 4, 6, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4, 0, 4, 4, 4, 5, 5, 5, 6, 4, 5,\n",
      "        5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 4, 5, 1, 4, 5, 4, 4, 5, 5, 5, 4, 5,\n",
      "        1, 5, 4, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 4, 4, 5, 5, 4, 4, 4, 4, 4, 5, 5,\n",
      "        4, 5, 4, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 5, 5, 4, 6, 4, 4, 5, 4, 5, 4,\n",
      "        4, 4, 5, 4, 4, 4, 4, 5, 1, 5, 4, 5, 4, 5, 4, 1, 5, 4, 5, 5, 4, 5, 5, 4,\n",
      "        5, 4, 5, 4, 4, 5, 4, 1, 5, 1, 4, 4, 1, 4, 4, 0, 5, 4, 4, 4, 4, 4, 1, 4,\n",
      "        4, 4, 4, 5, 4, 5, 4, 5, 4, 5, 5, 5, 4, 4, 5, 4, 4, 1, 4, 4, 4, 4, 4, 5,\n",
      "        4, 5, 5, 4, 4, 5, 5, 5, 4, 4, 1, 4, 4, 4, 5, 4, 5, 5, 1, 4, 5, 5, 1, 4,\n",
      "        5, 5, 5, 4, 4, 5, 5, 4, 0, 4, 4, 4, 4, 4, 6, 4, 4, 5, 4, 4, 5, 5, 4, 4,\n",
      "        4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4,\n",
      "        4, 4, 5, 4, 5, 4, 5, 4, 5, 4, 4, 5, 5, 4, 5, 4, 5, 5, 4, 4, 4, 5, 5, 5,\n",
      "        5, 5, 4, 5, 4, 5, 4, 4, 4, 5, 3, 5, 4, 4, 4, 4, 5, 4, 4, 5, 4, 5, 4, 4,\n",
      "        4, 5, 4, 4, 5, 4, 5, 4, 5, 4, 5, 5, 4, 4, 4, 5, 4, 5, 5, 5, 4, 4, 4, 1,\n",
      "        4, 4, 1, 5, 4, 5, 4, 4])\n",
      "tensor([4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 5, 4, 5, 4, 4, 4, 4, 5, 4, 4, 5, 5, 4, 4,\n",
      "        5, 5, 4, 4, 5, 4, 4, 5, 5, 4, 4, 4, 5, 5, 4, 4, 4, 5, 4, 4, 5, 5, 5, 4,\n",
      "        4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 5, 4, 5, 4, 1, 4, 4, 5,\n",
      "        4, 4, 5, 5, 5, 5, 4, 4, 1, 5, 4, 5, 4, 4, 5, 4, 5, 4, 4, 5, 4, 4, 5, 5,\n",
      "        5, 5, 4, 4, 5, 5, 4, 5, 5, 5, 4, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 4, 5, 6,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5,\n",
      "        4, 4, 4, 4, 5, 5, 4, 4, 4, 5, 5, 5, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 5, 0,\n",
      "        5, 4, 5, 5, 1, 5, 5, 5, 4, 4, 5, 5, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4,\n",
      "        4, 5, 0, 1, 4, 5, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "def read_pic(data, categories):\n",
    "    folder_path = 'images/'\n",
    "    image_paths = data.iloc[:, 1]\n",
    "    labels = data.iloc[:, 2].str.lower()\n",
    "    X = []\n",
    "    label_to_int = {category: i for i, category in enumerate(categories)}\n",
    "    integer_labels = labels.map(label_to_int)\n",
    "    y = torch.LongTensor(integer_labels.to_numpy())\n",
    "    for filename in image_paths:\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Check for common image file extensions\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (350, 350))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                X.append(torch.Tensor(img))\n",
    "    X = torch.stack(X).unsqueeze(1) # convert to pytorch tensor (batch, channels, w, h)\n",
    "    return X, y\n",
    "\n",
    "categories = [\n",
    "    \"anger\",\n",
    "    \"surprise\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"neutral\",\n",
    "    \"happiness\",\n",
    "    \"sadness\",\n",
    "    \"contempt\"\n",
    "]\n",
    "\n",
    "X, y = read_pic(pd.read_csv('data/legend.csv'), categories)\n",
    "X = X[:1000]\n",
    "y = y[:1000]\n",
    "seed = 1234\n",
    "Xtr, Xva, ytr, yva = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xva.shape)\n",
    "print(ytr)\n",
    "print(yva)\n",
    "\n",
    "batch_size = 512\n",
    "train_dataset = torch.utils.data.TensorDataset(Xtr, ytr)\n",
    "test_dataset = torch.utils.data.TensorDataset(Xva, yva)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4be595-d79b-485f-be8b-a660800dd9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(myDevice, myCNN, loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(myCNN.parameters(), lr=0.001, momentum=0.9)\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            inputs, labels = data[0].to(myDevice), data[1].to(myDevice)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = myCNN(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # print every 100 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "    return myCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5de725d-2d19-40c0-a2f2-c8ca16f84f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(myDevice, myCNN, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data[0].to(myDevice), data[1].to(myDevice)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = myCNN(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            return (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56f95b7-95f1-4260-a6d9-1e439f9849dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993839a5-8198-42e9-8f8e-f2b1ffbc45d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=112896, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=8, bias=True)\n",
      ")\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet(8).to(device)\n",
    "print(net)\n",
    "net = train_process(device, net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc96158-a177-43ef-b6f8-7b679e5b0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/cpu_test_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b80a93-f3c2-4142-8c73-87d9eef6b801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ConvNet(8).to(device)\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62291bb9-4139-4cd3-b4c8-3e0b1eac3f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 14.0625 %\n",
      "Testing Accuracy: 13.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy: {accuracy(device, net, trainloader) * 100} %')\n",
    "print(f'Testing Accuracy: {accuracy(device, net, testloader) * 100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

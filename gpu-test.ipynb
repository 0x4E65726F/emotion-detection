{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e459dc-ae41-4f86-bbcd-4890dffacfad",
   "metadata": {},
   "source": [
    "# CS 178 Project\n",
    "## Import part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db75ca5-8bbd-4c32-a91d-688546ed62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96ce5c-0330-4dbc-a5a9-ea68b7988ee8",
   "metadata": {},
   "source": [
    "## Read image for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2f9e24-af32-49c5-acb3-e9e1f192673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2,  ..., 5, 5, 5])\n",
      "tensor([5, 4, 0, 0, 0, 4, 0, 6, 4, 4, 0, 3, 3, 0, 4, 3, 4, 0, 3, 5, 0, 3, 6, 6,\n",
      "        5, 6, 5, 0, 0, 6, 5, 5, 5, 0, 5, 6, 4, 5, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5,\n",
      "        4, 0, 5, 5, 3, 5, 5, 4, 0, 5, 4, 3, 5, 5, 3, 5, 5, 3, 5, 5, 0, 5, 0, 3,\n",
      "        5, 0, 5, 5, 5, 5, 5, 0, 6, 4, 0, 4, 5, 4, 0, 3, 3, 5, 4, 0, 5, 0, 0, 5,\n",
      "        4, 0, 4, 0, 0, 0, 4, 4, 5, 5, 4, 6, 5, 5, 5, 0, 3, 6, 4, 4, 0, 4, 5, 5,\n",
      "        6, 0, 0, 0, 3, 3, 0, 5, 3, 0, 6, 0, 0, 0, 5, 0, 3, 5, 5, 4, 4, 4, 5, 0,\n",
      "        0, 0, 0, 3, 0, 0, 3, 3, 3, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 5, 4, 4, 3, 3,\n",
      "        3, 3, 3, 4, 3, 4, 4, 3, 4, 0, 0, 4, 6, 4, 4, 5, 0, 5, 0, 0, 5, 5, 5, 5,\n",
      "        5, 5, 5, 0, 4, 4, 5, 5, 6, 0, 4, 0, 0, 3, 3, 5, 3, 5, 5, 5, 5, 3, 0, 0,\n",
      "        0, 0, 5, 5, 0, 5, 5, 0, 6, 5, 4, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 0, 6, 4, 4, 4, 4, 0, 0, 0, 5, 5, 5, 4, 0, 5, 6,\n",
      "        4, 0, 0, 5, 5, 5, 0, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5,\n",
      "        5, 5, 5, 4, 5, 0, 0, 5, 5, 4, 4, 4, 0, 5, 6, 0, 5, 0, 4, 0, 5, 5, 5, 0,\n",
      "        6, 6, 6, 4, 5, 6, 6, 0, 5, 6, 0, 0, 4, 4, 4, 5, 5, 5, 5, 4, 5, 0, 5, 4,\n",
      "        4, 4, 5, 5, 5, 5, 0, 3, 4, 5, 5, 4, 4, 4, 6, 5, 0, 3, 4, 5, 5, 5, 3, 0,\n",
      "        5, 0, 0, 5, 5, 3, 5, 5, 5, 6, 5, 4, 6, 5, 5, 5, 0, 0, 0, 5, 3, 6, 6, 5,\n",
      "        6, 3, 5, 0, 3, 3, 3, 6, 5, 5, 5, 5, 3, 0, 5, 5, 5, 0, 6, 4, 0, 5, 3, 6,\n",
      "        6, 6, 6, 6, 5, 5, 5, 0, 5, 5, 4, 5, 5, 0, 5, 5, 0, 6, 5, 5, 6, 5, 5, 6,\n",
      "        5, 5, 3, 6, 5, 5, 6, 3, 6, 3, 3, 6, 3, 6, 0, 5, 5, 6, 6, 5, 5, 5, 5, 5,\n",
      "        6, 4, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 4, 4, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 6, 0, 5, 0, 0, 5, 4, 3, 6, 0, 4, 4, 4, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "def read_pic(data, categories):\n",
    "    folder_path = 'images/'\n",
    "    image_paths = data.iloc[:, 1]\n",
    "    labels = data.iloc[:, 2].str.lower()\n",
    "    X = []\n",
    "    label_to_int = {category: i for i, category in enumerate(categories)}\n",
    "    integer_labels = labels.map(label_to_int)\n",
    "    y = torch.LongTensor(integer_labels.to_numpy())\n",
    "    for filename in image_paths:\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Check for common image file extensions\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (350, 350))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            if img is not None:\n",
    "                X.append(torch.Tensor(img))\n",
    "    X = torch.stack(X).unsqueeze(1) # convert to pytorch tensor (batch, channels, w, h)\n",
    "    return X, y\n",
    "    \n",
    "categories1 = [\n",
    "    \"anger\", \n",
    "    \"surprise\", \n",
    "    \"disgust\", \n",
    "    \"fear\", \n",
    "    \"neutral\", \n",
    "    \"happiness\", \n",
    "    \"sadness\",\n",
    "    \"contempt\"\n",
    "] # This is for Legend\n",
    "categories2 = [\n",
    "    \"anger\", \n",
    "    \"surprise\", \n",
    "    \"disgust\", \n",
    "    \"fear\", \n",
    "    \"neutral\", \n",
    "    \"happiness\", \n",
    "    \"sad\",\n",
    "    \"contempt\"\n",
    "] # This is for 500_picts\n",
    "\n",
    "Xtr, ytr = read_pic(pd.read_csv('data/legend.csv'), categories1)\n",
    "Xva, yva = read_pic(pd.read_csv('data/500_picts_satz.csv'), categories2)\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xva.shape)\n",
    "print(ytr)\n",
    "print(yva)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c9460-26cb-4ccb-a236-e91efb32645c",
   "metadata": {},
   "source": [
    "## CNN Test\n",
    "### Define a Convolutional Neural Network\n",
    "To calculate the layer after each convolutional layer, we should do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb821a1d-c017-476a-96d1-2a16d5c6e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, conv_layer_channels, fc_layer_channels, kernel_size = 5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size) # 1 because its greyscale (in_channels, out_channels, kernel_size) (6, 350, 350) -> (6, 173, 173)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size) # (16, 84, 84)\n",
    "\n",
    "        # Linear Layer\n",
    "        self.fc1 = nn.Linear(16 * 84 * 84, 120) # shape of image after pooling twice (16, 84, 84)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 8) # 8 is label count\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv1 -> Pool -> Conv2 -> Pool -> Lin1 -> Lin2 -> Lin3\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net([6, 16], [120, 84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d347e528-c2d6-4768-8f7b-5b7e76977eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ytr)):\n",
    "    if ytr[i] < 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a03d6d-b18a-45ce-87cd-844a402385f2",
   "metadata": {},
   "source": [
    "### Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aaa6ce5-c02c-42ef-94fc-e36256bb5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde2d57-a17f-42de-9a15-4258fe028486",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc0b35c-05d1-4e0b-a23b-1486faf27ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.201\n",
      "[1,   200] loss: 0.082\n",
      "[1,   300] loss: 0.075\n",
      "[1,   400] loss: 0.064\n",
      "[1,   500] loss: 0.059\n",
      "[1,   600] loss: 0.055\n",
      "[1,   700] loss: 0.059\n",
      "[1,   800] loss: 0.057\n",
      "[1,   900] loss: 0.052\n",
      "[1,  1000] loss: 0.061\n",
      "[1,  1100] loss: 0.057\n",
      "[1,  1200] loss: 0.057\n",
      "[1,  1300] loss: 0.057\n",
      "[1,  1400] loss: 0.053\n",
      "[1,  1500] loss: 0.050\n",
      "[1,  1600] loss: 0.052\n",
      "[1,  1700] loss: 0.054\n",
      "[1,  1800] loss: 0.052\n",
      "[1,  1900] loss: 0.050\n",
      "[1,  2000] loss: 0.054\n",
      "[1,  2100] loss: 0.055\n",
      "[1,  2200] loss: 0.049\n",
      "[1,  2300] loss: 0.053\n",
      "[1,  2400] loss: 0.055\n",
      "[1,  2500] loss: 0.055\n",
      "[1,  2600] loss: 0.055\n",
      "[1,  2700] loss: 0.053\n",
      "[1,  2800] loss: 0.051\n",
      "[1,  2900] loss: 0.053\n",
      "[1,  3000] loss: 0.050\n",
      "[1,  3100] loss: 0.047\n",
      "[1,  3200] loss: 0.054\n",
      "[1,  3300] loss: 0.056\n",
      "[1,  3400] loss: 0.048\n",
      "[1,  3500] loss: 0.054\n",
      "[1,  3600] loss: 0.053\n",
      "[1,  3700] loss: 0.050\n",
      "[1,  3800] loss: 0.048\n",
      "[1,  3900] loss: 0.054\n",
      "[1,  4000] loss: 0.053\n",
      "[1,  4100] loss: 0.048\n",
      "[1,  4200] loss: 0.047\n",
      "[1,  4300] loss: 0.056\n",
      "[1,  4400] loss: 0.050\n",
      "[1,  4500] loss: 0.051\n",
      "[1,  4600] loss: 0.051\n",
      "[1,  4700] loss: 0.052\n",
      "[1,  4800] loss: 0.050\n",
      "[1,  4900] loss: 0.050\n",
      "[1,  5000] loss: 0.052\n",
      "[1,  5100] loss: 0.051\n",
      "[1,  5200] loss: 0.050\n",
      "[1,  5300] loss: 0.052\n",
      "[1,  5400] loss: 0.048\n",
      "[1,  5500] loss: 0.055\n",
      "[1,  5600] loss: 0.053\n",
      "[1,  5700] loss: 0.056\n",
      "[1,  5800] loss: 0.051\n",
      "[1,  5900] loss: 0.051\n",
      "[1,  6000] loss: 0.050\n",
      "[1,  6100] loss: 0.052\n",
      "[1,  6200] loss: 0.049\n",
      "[1,  6300] loss: 0.055\n",
      "[1,  6400] loss: 0.059\n",
      "[1,  6500] loss: 0.048\n",
      "[1,  6600] loss: 0.055\n",
      "[1,  6700] loss: 0.054\n",
      "[1,  6800] loss: 0.050\n",
      "[2,   100] loss: 0.057\n",
      "[2,   200] loss: 0.054\n",
      "[2,   300] loss: 0.050\n",
      "[2,   400] loss: 0.049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs) \n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cs178\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cs178\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cs178\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cs178\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cs178\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "train_dataset = torch.utils.data.TensorDataset(Xtr, ytr)\n",
    "test_dataset = torch.utils.data.TensorDataset(Xva, yva)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs) \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74e9d0-4e75-4f09-ae7d-dad3221f40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/test_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d9af5-91a5-4905-9c95-c9e96b41ed3e",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddb652-8e4f-4909-813e-bf5a1b0911c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net([6, 16], [120, 84])\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f2ce2-83c4-4abc-a17d-cf6bb1ed86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399f65d-7bc7-459f-9b40-b73a45faa64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
